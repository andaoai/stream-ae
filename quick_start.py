"""
æµå¼è§†é¢‘è‡ªç¼–ç å™¨å¿«é€Ÿå¯åŠ¨è„šæœ¬

æœ¬è„šæœ¬å®ç°äº†ä¸€ä¸ªæµå¼è§†é¢‘è‡ªç¼–ç å™¨çš„å¿«é€Ÿæ¼”ç¤ºå’Œæµ‹è¯•ç¯å¢ƒã€‚
ä¸»è¦ç‰¹æ€§ï¼š
- ä½¿ç”¨ObGDï¼ˆOnline Gradient Descentï¼‰ä¼˜åŒ–å™¨è¿›è¡Œåœ¨çº¿å­¦ä¹ 
- åŒæŸå¤±å‡½æ•°è®¾è®¡ï¼šç»†èŠ‚æŸå¤±å’Œå…¨å±€æŸå¤±
- æ”¯æŒå®æ—¶è§†é¢‘æµå¤„ç†å’Œå¯è§†åŒ–
- åŸºäºGymnasiumç¯å¢ƒè¿›è¡Œæµ‹è¯•

ä¼˜åŒ–å™¨è®¾è®¡å‚è€ƒï¼š
https://github.com/mohmdelsayed/streaming-drl
è¯¥é¡¹ç›®æä¾›äº†æµå¼æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„ä¼˜åŒ–å™¨å®ç°ï¼Œæˆ‘ä»¬å€Ÿé‰´äº†å…¶åœ¨çº¿æ¢¯åº¦ä¸‹é™çš„æ€æƒ³ã€‚

ä½œè€…ï¼šæµå¼AIå›¢é˜Ÿ
ç‰ˆæœ¬ï¼š1.0
æ—¥æœŸï¼š2024
"""

import torch
import torch.nn.functional as F
import numpy as np
import gymnasium as gym
from streaming_video_autoencoder import StreamingAutoEncoder, preprocess_frame
import matplotlib.pyplot as plt
from torch.utils.tensorboard import SummaryWriter
import os
from datetime import datetime

def quick_demo():
    """
    æµå¼è§†é¢‘è‡ªç¼–ç å™¨å¿«é€Ÿæ¼”ç¤º

    è¯¥å‡½æ•°æ¼”ç¤ºäº†æµå¼è§†é¢‘è‡ªç¼–ç å™¨çš„å®Œæ•´å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
    1. æ¨¡å‹åˆå§‹åŒ– - åˆ›å»ºå¸¦æœ‰ObGDä¼˜åŒ–å™¨çš„æµå¼è‡ªç¼–ç å™¨
    2. ç¯å¢ƒè®¾ç½® - åˆå§‹åŒ–Gymnasiumç¯å¢ƒï¼ˆä¼˜å…ˆä½¿ç”¨Atari Breakoutï¼‰
    3. åœ¨çº¿è®­ç»ƒ - ä½¿ç”¨æµå¼æ•°æ®è¿›è¡Œå®æ—¶è®­ç»ƒ
    4. ç»“æœå¯è§†åŒ– - ç”Ÿæˆè®­ç»ƒè¿‡ç¨‹çš„è¯¦ç»†å›¾è¡¨
    5. æ€§èƒ½åˆ†æ - è®¡ç®—æ”¶æ•›æ€§å’Œæ”¹å–„æŒ‡æ ‡
    6. æ¨¡å‹ä¿å­˜ - ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡

    ä¼˜åŒ–å™¨ç‰¹æ€§ï¼ˆå‚è€ƒstreaming-drlé¡¹ç›®ï¼‰ï¼š
    - ObGDï¼ˆOnline Gradient Descentï¼‰ï¼šé€‚ç”¨äºæµå¼æ•°æ®çš„åœ¨çº¿å­¦ä¹ 
    - åŒæŸå¤±å‡½æ•°ï¼šç»†èŠ‚æŸå¤±å…³æ³¨å±€éƒ¨ç‰¹å¾ï¼Œå…¨å±€æŸå¤±å…³æ³¨æ•´ä½“ç»“æ„
    - è‡ªé€‚åº”å­¦ä¹ ç‡ï¼šæ ¹æ®æ¢¯åº¦å˜åŒ–åŠ¨æ€è°ƒæ•´å­¦ä¹ æ­¥é•¿
    - å†…å­˜æ•ˆç‡ï¼šé¿å…å­˜å‚¨å†å²æ•°æ®ï¼Œé€‚åˆé•¿æ—¶é—´è¿è¡Œ

    Returns:
        tuple: (model, losses) åŒ…å«è®­ç»ƒå¥½çš„æ¨¡å‹å’ŒæŸå¤±å†å²
            - model (StreamingAutoEncoder): è®­ç»ƒå®Œæˆçš„è‡ªç¼–ç å™¨æ¨¡å‹
            - losses (dict): åŒ…å«å„ç±»æŸå¤±å€¼çš„å­—å…¸
                - 'detail': ç»†èŠ‚æŸå¤±å†å²
                - 'global': å…¨å±€æŸå¤±å†å²
                - 'mse': MSEæŸå¤±å†å²
                - 'changed_pixels': å˜åŒ–åƒç´ æ•°é‡å†å²
    """
    print("æµå¼è§†é¢‘è‡ªç¼–ç å™¨å¿«é€Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # 1. åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºæµå¼è‡ªç¼–ç å™¨æ¨¡å‹...")
    model = StreamingAutoEncoder(
        input_channels=3,        # RGBå›¾åƒè¾“å…¥é€šé“æ•°
        base_channels=8,         # ç¼–ç å™¨èµ·å§‹é€šé“æ•°ï¼ˆè½»é‡åŒ–è®¾è®¡ï¼‰
        latent_channels=16,      # æ½œåœ¨ç©ºé—´ç»´åº¦
        lr=0.001,               # ObGDä¼˜åŒ–å™¨å­¦ä¹ ç‡ï¼ˆå‚è€ƒstreaming-drlè°ƒä¼˜ï¼‰
        gamma=0.99,             # åŠ¨é‡è¡°å‡å› å­ï¼Œç”¨äºæ¢¯åº¦å¹³æ»‘
        lamda=0.8,              # æŸå¤±å‡½æ•°æƒé‡å¹³è¡¡å‚æ•°
        kappa=1.5,              # æŸå¤±ç¨³å®šæ€§å‚æ•°
        debug_vis=True,         # å¯ç”¨è°ƒè¯•å¯è§†åŒ–
        use_tensorboard=True,   # å¯ç”¨TensorBoardæ—¥å¿—è®°å½•
        log_dir="runs/quick_demo"  # æŒ‡å®šæ—¥å¿—ç›®å½•
    )

    print(f"æ¨¡å‹åˆ›å»ºæˆåŠŸï¼å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # 2. åˆ›å»ºç¯å¢ƒ
    print("\nåˆ›å»ºGymç¯å¢ƒ...")
    try:
        env = gym.make('ALE/Breakout-v5', render_mode='rgb_array')
        obs, _ = env.reset()
        print(f"ç¯å¢ƒåˆ›å»ºæˆåŠŸï¼è§‚å¯Ÿç©ºé—´: {obs.shape}")
    except:
        print("Atariç¯å¢ƒä¸å¯ç”¨ï¼Œä½¿ç”¨CartPoleæ›¿ä»£...")
        env = gym.make('CartPole-v1', render_mode='rgb_array')
        obs, _ = env.reset()
        print(f"CartPoleç¯å¢ƒåˆ›å»ºæˆåŠŸï¼è§‚å¯Ÿç©ºé—´: {obs.shape}")
    
    # 3. å¿«é€Ÿè®­ç»ƒ - æµå¼åœ¨çº¿å­¦ä¹ è¿‡ç¨‹
    print("\nå¼€å§‹å¿«é€Ÿè®­ç»ƒ...")
    num_frames = 500000  # è®­ç»ƒå¸§æ•°ï¼Œè¶³å¤Ÿè§‚å¯Ÿæ”¶æ•›è¡Œä¸º
    losses = {'global': [], 'mse': [], 'changed_pixels': []}

    for frame_idx in range(num_frames):
        # é¢„å¤„ç†å¸§ï¼šæ ‡å‡†åŒ–åˆ°[0,1]èŒƒå›´ï¼Œè°ƒæ•´ç»´åº¦ä¸º[1,C,H,W]
        curr_frame = preprocess_frame(obs)

        # æ ¸å¿ƒï¼šä½¿ç”¨ObGDä¼˜åŒ–å™¨è¿›è¡Œåœ¨çº¿å‚æ•°æ›´æ–°
        # è¿™é‡Œå®ç°äº†streaming-drlé¡¹ç›®ä¸­çš„åœ¨çº¿å­¦ä¹ æ€æƒ³ï¼š
        # - æ— éœ€å­˜å‚¨å†å²æ•°æ®
        # - å®æ—¶è®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°å‚æ•°
        # - åŒæŸå¤±å‡½æ•°åŒæ—¶ä¼˜åŒ–å±€éƒ¨å’Œå…¨å±€ç‰¹å¾
        results = model.update_params(curr_frame, debug=(frame_idx % 10 == 0))

        # è®°å½•è®­ç»ƒæŒ‡æ ‡ç”¨äºåç»­åˆ†æ
        losses['global'].append(results['global_loss'])      # å…¨å±€æŸå¤±ï¼ˆæ•´ä½“ç»“æ„ï¼‰
        losses['mse'].append(results['mse_loss'])            # é‡å»ºè¯¯å·®
        losses['changed_pixels'].append(results['changed_pixels'])  # å˜åŒ–æ£€æµ‹

        # ç¯å¢ƒäº¤äº’ï¼šéšæœºåŠ¨ä½œç­–ç•¥ï¼ˆç”¨äºæ•°æ®å¤šæ ·æ€§ï¼‰
        action = env.action_space.sample()
        obs, reward, terminated, truncated, info = env.step(action)

        # å¤„ç†episodeç»“æŸï¼šé‡ç½®ç¯å¢ƒå’Œæ¨¡å‹çŠ¶æ€
        if terminated or truncated:
            obs, _ = env.reset()
            model.prev_frame = None      # æ¸…é™¤å‰ä¸€å¸§ç¼“å­˜
            model.prev_embedding = None  # æ¸…é™¤å‰ä¸€å¸§ç¼–ç 

        # è®­ç»ƒè¿›åº¦ç›‘æ§
        if frame_idx % 1000 == 0:
            print(f"å¸§ {frame_idx+1}/{num_frames} - "
                  f"Global: {results['global_loss']:.1f}, "
                  f"MSE: {results['mse_loss']:.1f}")
    
    env.close()
    
    # å…³é—­TensorBoardå†™å…¥å™¨
    model.close_tensorboard()
    
    # 4. ç»“æœå¯è§†åŒ– - ä¸“æ³¨äºå·ç§¯æ ¸è¾“å‡º
    print("\nç”Ÿæˆç»“æœå¯è§†åŒ–...")
    print("TensorBoardæ—¥å¿—å·²ä¿å­˜ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹:")
    print("tensorboard --logdir=runs/quick_demo")
    print("ç„¶ååœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ http://localhost:6006")
    print("\nTensorBoardä¸­å¯ä»¥çœ‹åˆ°:")
    print("ğŸ“Š æŸå¤±æ›²çº¿: å…¨å±€æŸå¤±ã€MSEæŸå¤±ã€SSIMæŸå¤±")
    print("ğŸ–¼ï¸ å›¾åƒå¯¹æ¯”: åŸå§‹è¾“å…¥ vs é‡å»ºè¾“å‡º")
    print("ğŸ” é‡å»ºè¯¯å·®: åƒç´ çº§å·®å¼‚å›¾")
    print("ğŸ¯ å·ç§¯æ ¸è¾“å‡º:")
    print("   - å°å·ç§¯(3Ã—3): çº¹ç†ç‰¹å¾ - 27Ã—27Ã—16")
    print("   - ä¸­å·ç§¯(5Ã—5): å¹³è¡¡ç‰¹å¾ - 25Ã—25Ã—16") 
    print("   - å¤§å·ç§¯(7Ã—7): ç»“æ„ç‰¹å¾ - 23Ã—23Ã—16")
    print("ğŸ“ˆ Embeddingç»Ÿè®¡: å‡å€¼ã€æ ‡å‡†å·®ã€æœ€å¤§å€¼")
    
    # ç”Ÿæˆå·ç§¯æ ¸è¾“å‡ºå¯¹æ¯”å›¾
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('å¹¶è¡Œå¤šå°ºåº¦å·ç§¯æ ¸è¾“å‡ºåˆ†æ', fontsize=16)
    
    # æŸå¤±è¶‹åŠ¿
    frames = range(min(len(losses['global']), 10000))  # åªæ˜¾ç¤ºå‰10000å¸§
    axes[0, 0].plot(frames, losses['global'][:len(frames)], 'r-', linewidth=2)
    axes[0, 0].set_title('å…¨å±€æŸå¤±è¶‹åŠ¿')
    axes[0, 0].set_xlabel('å¸§æ•°')
    axes[0, 0].set_ylabel('æŸå¤±å€¼')
    axes[0, 0].grid(True, alpha=0.3)
    
    axes[0, 1].plot(frames, losses['mse'][:len(frames)], 'g-', linewidth=2)
    axes[0, 1].set_title('MSEæŸå¤±è¶‹åŠ¿')
    axes[0, 1].set_xlabel('å¸§æ•°')
    axes[0, 1].set_ylabel('MSEæŸå¤±')
    axes[0, 1].grid(True, alpha=0.3)
    
    axes[0, 2].plot(frames, losses['changed_pixels'][:len(frames)], 'm-', linewidth=2)
    axes[0, 2].set_title('å˜åŒ–åƒç´ æ•°é‡')
    axes[0, 2].set_xlabel('å¸§æ•°')
    axes[0, 2].set_ylabel('åƒç´ æ•°')
    axes[0, 2].grid(True, alpha=0.3)
    
    # å·ç§¯æ ¸è¾“å‡ºç¤ºæ„å›¾
    # å°å·ç§¯åˆ†æ”¯ (3Ã—3) - çº¹ç†ç‰¹å¾
    small_demo = np.random.rand(16, 27, 27)
    axes[1, 0].imshow(small_demo[0], cmap='viridis')
    axes[1, 0].set_title('å°å·ç§¯(3Ã—3)è¾“å‡ºç¤ºä¾‹\nçº¹ç†ç‰¹å¾ - 27Ã—27Ã—16\nå‹ç¼©æ¯”: 69:1')
    axes[1, 0].axis('off')
    
    # ä¸­å·ç§¯åˆ†æ”¯ (5Ã—5) - å¹³è¡¡ç‰¹å¾
    medium_demo = np.random.rand(16, 25, 25)
    axes[1, 1].imshow(medium_demo[0], cmap='plasma')
    axes[1, 1].set_title('ä¸­å·ç§¯(5Ã—5)è¾“å‡ºç¤ºä¾‹\nå¹³è¡¡ç‰¹å¾ - 25Ã—25Ã—16\nå‹ç¼©æ¯”: 80:1')
    axes[1, 1].axis('off')
    
    # å¤§å·ç§¯åˆ†æ”¯ (7Ã—7) - ç»“æ„ç‰¹å¾
    large_demo = np.random.rand(16, 23, 23)
    axes[1, 2].imshow(large_demo[0], cmap='inferno')
    axes[1, 2].set_title('å¤§å·ç§¯(7Ã—7)è¾“å‡ºç¤ºä¾‹\nç»“æ„ç‰¹å¾ - 23Ã—23Ã—16\nå‹ç¼©æ¯”: 95:1')
    axes[1, 2].axis('off')
    
    plt.tight_layout()
    plt.savefig('parallel_multi_scale_analysis.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    # 5. ç»“æœåˆ†æ
    print("\nè®­ç»ƒç»“æœåˆ†æ:")
    print(f"   å¹³å‡å…¨å±€æŸå¤±: {np.mean(losses['global']):.6f}")
    print(f"   å¹³å‡MSEæŸå¤±: {np.mean(losses['mse']):.6f}")
    print(f"   å¹³å‡å˜åŒ–åƒç´ : {np.mean(losses['changed_pixels']):.0f}")
    
    # æ”¶æ•›æ€§åˆ†æ
    if len(losses['global']) > 10:
        early_global = np.mean(losses['global'][:10])
        late_global = np.mean(losses['global'][-10:])
        global_improvement = (early_global - late_global) / early_global * 100
        
        early_mse = np.mean(losses['mse'][:10])
        late_mse = np.mean(losses['mse'][-10:])
        mse_improvement = (early_mse - late_mse) / early_mse * 100
        
        print(f"   å…¨å±€æŸå¤±æ”¹å–„: {global_improvement:.1f}%")
        print(f"   MSEæŸå¤±æ”¹å–„: {mse_improvement:.1f}%")
    
    # 6. ä¿å­˜æ¨¡å‹
    print("\nä¿å­˜æ¨¡å‹...")
    torch.save(model.state_dict(), 'quick_demo_model.pth')
    print("æ¨¡å‹å·²ä¿å­˜åˆ° quick_demo_model.pth")

    print("\nå¿«é€Ÿæ¼”ç¤ºå®Œæˆï¼")
    print("ç”Ÿæˆæ–‡ä»¶:")
    print("   - parallel_multi_scale_analysis.png: å¹¶è¡Œå¤šå°ºåº¦å·ç§¯æ ¸åˆ†æ")
    print("   - quick_demo_model.pth: è®­ç»ƒå¥½çš„æ¨¡å‹")
    print("   - runs/quick_demo/: TensorBoardæ—¥å¿—ç›®å½•")
    
    return model, losses

def test_model_inference():
    """
    æµ‹è¯•æ¨¡å‹æ¨ç†èƒ½åŠ›

    è¯¥å‡½æ•°ç”¨äºæµ‹è¯•è®­ç»ƒå®Œæˆçš„æµå¼è‡ªç¼–ç å™¨çš„æ¨ç†æ€§èƒ½ï¼ŒåŒ…æ‹¬ï¼š
    1. æ¨¡å‹åŠ è½½ - å°è¯•åŠ è½½é¢„è®­ç»ƒæƒé‡æˆ–ä½¿ç”¨éšæœºåˆå§‹åŒ–
    2. æ¨ç†æµ‹è¯• - ä½¿ç”¨éšæœºè¾“å…¥æµ‹è¯•é‡å»ºèƒ½åŠ›
    3. æ€§èƒ½è¯„ä¼° - è®¡ç®—é‡å»ºè¯¯å·®ï¼ˆMSEï¼‰
    4. ç»“æœå¯è§†åŒ– - æ˜¾ç¤ºåŸå§‹è¾“å…¥ã€é‡å»ºè¾“å‡ºå’Œembeddingè¡¨ç¤º

    è¯¥æµ‹è¯•éªŒè¯äº†ObGDä¼˜åŒ–å™¨è®­ç»ƒçš„æ¨¡å‹æ˜¯å¦å…·å¤‡ï¼š
    - è‰¯å¥½çš„é‡å»ºèƒ½åŠ›ï¼ˆä½MSEè¯¯å·®ï¼‰
    - æœ‰æ„ä¹‰çš„æ½œåœ¨è¡¨ç¤ºï¼ˆembeddingå¯è§†åŒ–ï¼‰
    - ç¨³å®šçš„æ¨ç†æ€§èƒ½ï¼ˆæ— æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±ï¼‰

    Returns:
        float: é‡å»ºè¯¯å·®ï¼ˆMSEï¼‰ï¼Œç”¨äºé‡åŒ–æ¨¡å‹æ€§èƒ½
    """
    print("\næµ‹è¯•æ¨¡å‹æ¨ç†èƒ½åŠ›...")

    # åŠ è½½æ¨¡å‹ - ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ¶æ„
    model = StreamingAutoEncoder(
        input_channels=3,        # RGBè¾“å…¥
        base_channels=8,         # ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„å‚æ•°
        latent_channels=16       # ä¿æŒä¸è®­ç»ƒæ—¶ä¸€è‡´çš„æ½œåœ¨ç»´åº¦
    )

    try:
        model.load_state_dict(torch.load('quick_demo_model.pth'))
        print("æ¨¡å‹åŠ è½½æˆåŠŸ")
    except:
        print("æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
    
    model.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    test_input = torch.rand(1, 3, 64, 64)
    
    with torch.no_grad():
        reconstruction, embedding = model(test_input)
    
    mse_error = F.mse_loss(test_input, reconstruction).item()
    
    print(f"æ¨ç†ç»“æœ:")
    print(f"   è¾“å…¥å½¢çŠ¶: {test_input.shape}")
    print(f"   é‡å»ºå½¢çŠ¶: {reconstruction.shape}")
    print(f"   Embeddingå½¢çŠ¶: {embedding.shape}")
    print(f"   é‡å»ºè¯¯å·®: {mse_error:.6f}")
    
    # å¯è§†åŒ–æ¨ç†ç»“æœ
    fig, axes = plt.subplots(1, 3, figsize=(12, 4))
    
    axes[0].imshow(test_input[0].permute(1, 2, 0))
    axes[0].set_title('åŸå§‹è¾“å…¥')
    axes[0].axis('off')
    
    axes[1].imshow(reconstruction[0].permute(1, 2, 0))
    axes[1].set_title(f'é‡å»ºè¾“å‡º\nMSE: {mse_error:.4f}')
    axes[1].axis('off')
    
    # Embeddingå¯è§†åŒ–
    emb_2d = embedding[0].reshape(8, 4)  # 32ç»´é‡å¡‘ä¸º8x4
    im = axes[2].imshow(emb_2d, cmap='viridis')
    axes[2].set_title('Embeddingè¡¨ç¤º')
    axes[2].axis('off')
    plt.colorbar(im, ax=axes[2])
    
    plt.tight_layout()
    plt.savefig('inference_test.png', dpi=150)
    plt.show()
    
    return mse_error

def live_viewer():
    """
    å®æ—¶å¯è§†åŒ–æŸ¥çœ‹å™¨ - TensorBoardç‰ˆæœ¬

    è¯¥å‡½æ•°æä¾›äº†æµå¼è§†é¢‘è‡ªç¼–ç å™¨çš„å®æ—¶å¯è§†åŒ–ç•Œé¢ï¼Œä½¿ç”¨TensorBoardè¿›è¡Œç›‘æ§ï¼š
    1. å®æ—¶ç›‘æ§ - é€šè¿‡TensorBoardæ˜¾ç¤ºå½“å‰å¸§ã€é‡å»ºè¾“å‡ºå’Œå·®å¼‚å›¾
    2. æŸå¤±è¿½è¸ª - å®æ—¶è®°å½•ç»†èŠ‚æŸå¤±ã€å…¨å±€æŸå¤±å’ŒMSEæŸå¤±åˆ°TensorBoard
    3. ç‰¹å¾å¯è§†åŒ– - è®°å½•ç¼–ç å™¨å’Œè§£ç å™¨å„å±‚çš„ç‰¹å¾å›¾åˆ°TensorBoard
    4. æ€§èƒ½åˆ†æ - é€šè¿‡TensorBoardæ£€æµ‹ç»†èŠ‚ä¸¢å¤±å’Œé‡å»ºè´¨é‡

    TensorBoardåŠŸèƒ½ï¼š
    - å®æ—¶æŸå¤±æ›²çº¿å’ŒæŒ‡æ ‡ç›‘æ§
    - å›¾åƒé‡å»ºè´¨é‡å¯è§†åŒ–
    - ç‰¹å¾å›¾å±‚çº§åˆ†æ
    - æ¨¡å‹å‚æ•°åˆ†å¸ƒç›‘æ§
    - äº¤äº’å¼è°ƒè¯•ç•Œé¢

    æ§åˆ¶ï¼š
    - Ctrl+C: åœæ­¢è¿è¡Œ
    - TensorBoard: åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹ http://localhost:6006
    """
    print("Real-time Live Viewer with TensorBoard")
    print("TensorBoardå°†åœ¨æµè§ˆå™¨ä¸­æ˜¾ç¤ºå®æ—¶ç›‘æ§ä¿¡æ¯")
    print("å¯åŠ¨TensorBoard: tensorboard --logdir=runs/live_viewer")

    # Load model with TensorBoard enabled
    model = StreamingAutoEncoder(
        input_channels=3, 
        base_channels=8, 
        latent_channels=16, 
        lr=0.0001, 
        debug_vis=True,
        use_tensorboard=True,
        log_dir="runs/live_viewer"
    )
    try:
        model.load_state_dict(torch.load('quick_demo_model.pth'))
        print("Model loaded")
    except:
        print("Using untrained model")

    # Setup environment
    env = gym.make('ALE/Breakout-v5', render_mode='rgb_array')
    obs, _ = env.reset()

    prev_frame = None
    frame_count = 0

    try:
        print("Press Ctrl+C to stop")
        print("åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œ: tensorboard --logdir=runs/live_viewer")
        print("ç„¶ååœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: http://localhost:6006")
        i = 0
        while True:  # æŒç»­è¿è¡Œ
            # Process current frame
            curr_frame = preprocess_frame(obs)
            results = model.update_params(curr_frame, debug=(i % 100 == 0))

            # Environment step
            prev_frame = curr_frame.clone()
            action = env.action_space.sample()
            obs, _, done, truncated, _ = env.step(action)

            if done or truncated:
                obs, _ = env.reset()
                model.prev_frame = None

            frame_count += 1
            i += 1

            # å®šæœŸè¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            if i % 100 == 0:
                print(f"Frame {i}: Global={results['global_loss']:.3f}, MSE={results['mse_loss']:.3f}")
                print(f"  Changed Pixels={results['changed_pixels']:.0f}")

    except KeyboardInterrupt:
        print("Stopped by user")
    finally:
        env.close()
        model.close_tensorboard()
        print("Live viewer finished")

def main():
    """
    ä¸»å‡½æ•° - æµå¼è§†é¢‘è‡ªç¼–ç å™¨æ¼”ç¤ºç¨‹åºå…¥å£

    æä¾›ä¸¤ç§è¿è¡Œæ¨¡å¼ï¼š
    1. Quick Demo (é»˜è®¤) - å®Œæ•´çš„è®­ç»ƒã€æµ‹è¯•å’Œåˆ†ææµç¨‹
       - è‡ªåŠ¨è®­ç»ƒæ¨¡å‹500,000å¸§
       - ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š
       - ä¿å­˜è®­ç»ƒç»“æœå’Œå¯è§†åŒ–å›¾è¡¨
       - é€‚åˆæ‰¹é‡å®éªŒå’Œæ€§èƒ½è¯„ä¼°

    2. Live Viewer - å®æ—¶å¯è§†åŒ–ç›‘æ§ç•Œé¢
       - å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹
       - å¤šç»´åº¦æ€§èƒ½ç›‘æ§
       - äº¤äº’å¼è°ƒè¯•åŠŸèƒ½
       - é€‚åˆå¼€å‘è°ƒè¯•å’Œæ¼”ç¤ºå±•ç¤º

    æŠ€æœ¯ç‰¹æ€§ï¼š
    - åŸºäºstreaming-drlçš„ObGDä¼˜åŒ–å™¨
    - åŒæŸå¤±å‡½æ•°è®¾è®¡ï¼ˆç»†èŠ‚+å…¨å±€ï¼‰
    - å†…å­˜é«˜æ•ˆçš„æµå¼å¤„ç†
    - å®æ—¶æ€§èƒ½ç›‘æ§å’Œå¯è§†åŒ–
    """
    print("Streaming Video Autoencoder with TensorBoard")
    print("åŸºäºstreaming-drlé¡¹ç›®çš„ObGDä¼˜åŒ–å™¨å®ç°")
    print("=" * 50)
    print("1. Quick Demo  - å®Œæ•´è®­ç»ƒå’Œåˆ†ææµç¨‹ (TensorBoard)")
    print("2. Live Viewer - å®æ—¶å¯è§†åŒ–ç›‘æ§ (TensorBoard)")
    print("=" * 50)
    print("TensorBoardåŠŸèƒ½:")
    print("  - å®æ—¶æŸå¤±æ›²çº¿å’ŒæŒ‡æ ‡ç›‘æ§")
    print("  - å›¾åƒé‡å»ºè´¨é‡å¯è§†åŒ–")
    print("  - ä¸‰ä¸ªå·ç§¯åˆ†æ”¯è¾“å‡ºç‰¹å¾å›¾:")
    print("    * å°å·ç§¯(3Ã—3): çº¹ç†ç‰¹å¾ - 27Ã—27Ã—16")
    print("    * ä¸­å·ç§¯(5Ã—5): å¹³è¡¡ç‰¹å¾ - 25Ã—25Ã—16")
    print("    * å¤§å·ç§¯(7Ã—7): ç»“æ„ç‰¹å¾ - 23Ã—23Ã—16")
    print("  - Embeddingç»Ÿè®¡ä¿¡æ¯ç›‘æ§")
    print("  - æ¨¡å‹å‚æ•°åˆ†å¸ƒç›‘æ§")
    print("=" * 50)

    try:
        choice = input("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼ (1 æˆ– 2ï¼Œé»˜è®¤1): ").strip()
    except (EOFError, KeyboardInterrupt):
        choice = "1"  # é»˜è®¤é€‰æ‹©å¿«é€Ÿæ¼”ç¤º

    if choice == "2":
        live_viewer()
    else:
        # è¿è¡Œå¿«é€Ÿæ¼”ç¤º
        print("å¯åŠ¨å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼...")
        model, losses = quick_demo()
        test_model_inference()

if __name__ == "__main__":
    main()
